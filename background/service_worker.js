import { createCostTracker, DEFAULT_LIMIT_USD } from '../utils/cost.js';
import { fetchApiKeyDetails, readApiKey, saveApiKey } from '../utils/apiKeyStore.js';
import { getValue, setValue, withLock, getSessionValue, setSessionValue, runtime } from '../utils/storage.js';

/**
 * Background service worker responsible for orchestrating OpenAI requests,
 * maintaining cached summaries, and persisting usage data for the extension.
 *
 * The worker exposes a message-based API consumed by the popup UI and content
 * scripts. It keeps secrets inside the background context to avoid leaking the
 * OpenAI API key to content pages.
 *
 * @module background/service_worker
 */

const USAGE_STORAGE_KEY = 'comet:usage';
const CACHE_STORAGE_KEY = 'comet:cache';

let costTracker;
let memoryCache = new Map();
let initialised = false;

/**
 * Builds a deterministic cache key for a page segment.
 *
 * @param {string} url - The origin URL for the segment.
 * @param {string|number} segmentId - Identifier generated by the content script.
 * @returns {string} Composite key for lookups in the in-memory cache.
 */
function getCacheKey(url, segmentId) {
  return `${url}::${segmentId}`;
}

/**
 * Lazily initialises the cost tracker and cache using stored values.
 *
 * The operation is idempotent and safe to call repeatedly.
 * @returns {Promise<void>} Resolves once usage and cache state are hydrated.
 */
async function ensureInitialised() {
  if (initialised) {
    return;
  }
  const storedUsage = await getValue(USAGE_STORAGE_KEY);
  let limitUsd = DEFAULT_LIMIT_USD;
  let usage;

  if (storedUsage && typeof storedUsage === 'object') {
    const { limitUsd: savedLimit, ...snapshot } = storedUsage;
    if (typeof savedLimit === 'number' && Number.isFinite(savedLimit)) {
      limitUsd = savedLimit;
    }
    usage = Object.keys(snapshot).length > 0 ? snapshot : undefined;
  }

  costTracker = createCostTracker(limitUsd, usage);
  const cachedEntries = (await getSessionValue(CACHE_STORAGE_KEY)) || {};
  memoryCache = new Map(Object.entries(cachedEntries));
  initialised = true;
}

/**
 * Persists the current usage snapshot to extension storage with a simple lock
 * to avoid concurrent writes from overlapping requests.
 *
 * @returns {Promise<void>} Resolves once the usage payload is stored.
 */
async function persistUsage() {
  await withLock(USAGE_STORAGE_KEY, async () => {
    await setValue(USAGE_STORAGE_KEY, costTracker.toJSON());
  });
}

/**
 * Writes the summarisation cache into the session storage area so it can be
 * reused within the same browser session.
 *
 * @returns {Promise<void>} Resolves once cached entries are synchronised.
 */
async function persistCache() {
  const entries = Object.fromEntries(memoryCache.entries());
  await setSessionValue(CACHE_STORAGE_KEY, entries);
}

/**
 * Retrieves the stored OpenAI API key.
 *
 * @returns {Promise<string|null>} The API key if present, otherwise null.
 */
async function getApiKey() {
  return readApiKey();
}

/**
 * Stores the provided OpenAI API key or clears it when falsy.
 *
 * @param {string|null|undefined} apiKey - API key captured from the popup UI.
 * @returns {Promise<string|null>} The persisted API key or null when removed.
 */
async function setApiKey(apiKey) {
  return saveApiKey(apiKey);
}

/**
 * Retrieves the stored API key alongside metadata for UI display.
 *
 * @returns {Promise<{apiKey: string|null, lastUpdated: number|null}>} Key details.
 */
async function getApiKeyDetails() {
  return fetchApiKeyDetails();
}

/**
 * Validates that an API key is available before performing remote calls.
 *
 * @param {string|null|undefined} apiKey - Candidate API key.
 * @throws {Error} When the key is missing.
 */
function ensureKeyAvailable(apiKey) {
  if (!apiKey) {
    throw new Error('Missing OpenAI API key.');
  }
}

/**
 * Converts an ArrayBuffer into a Base64 string.
 *
 * @param {ArrayBuffer} arrayBuffer - Raw binary audio data.
 * @returns {string} Base64 encoded representation.
 */
function toBase64(arrayBuffer) {
  const bytes = new Uint8Array(arrayBuffer);
  let binary = '';
  bytes.forEach(byte => {
    binary += String.fromCharCode(byte);
  });
  return btoa(binary);
}

/**
 * Executes a fetch call against the OpenAI API with the stored credentials.
 *
 * @param {string} endpoint - API endpoint path, e.g. `/v1/chat/completions`.
 * @param {RequestInit} [options] - Additional fetch options.
 * @returns {Promise<Response>} Resolved HTTP response when successful.
 * @throws {Error} When the API response is not ok.
 */
async function fetchWithAuth(endpoint, options = {}) {
  const apiKey = await getApiKey();
  ensureKeyAvailable(apiKey);

  const response = await fetch(`https://api.openai.com${endpoint}`, {
    ...options,
    headers: {
      'Content-Type': 'application/json',
      Authorization: `Bearer ${apiKey}`,
      ...options.headers,
    },
  });

  if (!response.ok) {
    const message = await response.text();
    throw new Error(`OpenAI error (${response.status}): ${message}`);
  }

  return response;
}

/**
 * Requests a spoken-summary friendly completion from OpenAI.
 *
 * @param {Object} params - Chat completion parameters.
 * @param {string} params.text - Segment text to summarise.
 * @param {string} params.url - Page URL associated with the segment.
 * @param {string} params.segmentId - Identifier for the source segment.
 * @param {string} params.language - Target language for the summary.
 * @param {string} [params.model='gpt-4o-mini'] - Model identifier.
 * @returns {Promise<string>} Generated summary text.
 */
async function sendChatCompletion({ text, url, segmentId, language, model = 'gpt-4o-mini' }) {
  const prompt = `Provide a concise, listener-friendly summary of the following webpage content. Use ${language} language.\n\n${text}`;

  const response = await fetchWithAuth('/v1/chat/completions', {
    method: 'POST',
    body: JSON.stringify({
      model,
      temperature: 0.3,
      messages: [
        { role: 'system', content: 'You are a helpful assistant that creates short spoken summaries.' },
        { role: 'user', content: prompt },
      ],
    }),
  });

  const data = await response.json();
  const choice = data.choices && data.choices[0];
  const summary = choice && choice.message && choice.message.content ? choice.message.content.trim() : '';

  const promptTokens = data.usage?.prompt_tokens || costTracker.estimateTokensFromText(text);
  const completionTokens = data.usage?.completion_tokens || costTracker.estimateTokensFromText(summary);
  costTracker.record(model, promptTokens, completionTokens, {
    url,
    segmentId,
    type: 'summary',
  });
  await persistUsage();

  return summary;
}

/**
 * Sends recorded audio to OpenAI for transcription while applying cost
 * controls.
 *
 * @param {Object} params - Transcription payload.
 * @param {string} params.base64 - Base64 encoded audio data.
 * @param {string} [params.filename='speech.webm'] - Logical file name for logs.
 * @param {string} [params.mimeType='audio/webm'] - Audio media type.
 * @returns {Promise<string>} Transcribed text.
 */
async function transcribeAudio({ base64, filename = 'speech.webm', mimeType = 'audio/webm' }) {
  const apiKey = await getApiKey();
  ensureKeyAvailable(apiKey);
  const estimatedCost = 0.005;
  if (!costTracker.canSpend(estimatedCost)) {
    throw new Error('Cost limit reached for transcription.');
  }

  const formData = new FormData();
  const blob = new Blob([Uint8Array.from(atob(base64), c => c.charCodeAt(0))], { type: mimeType });
  formData.append('file', blob, filename);
  formData.append('model', 'gpt-4o-mini-transcribe');

  const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
    method: 'POST',
    headers: {
      Authorization: `Bearer ${apiKey}`,
    },
    body: formData,
  });

  if (!response.ok) {
    const message = await response.text();
    throw new Error(`Transcription failed (${response.status}): ${message}`);
  }

  const data = await response.json();
  costTracker.recordFlat('stt', estimatedCost, { type: 'stt' });
  await persistUsage();
  return data.text;
}

/**
 * Requests a speech synthesis response from OpenAI based on summary text.
 *
 * @param {Object} params - Speech synthesis payload.
 * @param {string} params.text - Text to convert into audio.
 * @param {string} [params.voice='alloy'] - Voice preset requested.
 * @param {string} [params.format='mp3'] - Target audio encoding.
 * @param {string} [params.model='gpt-4o-mini-tts'] - Model identifier.
 * @returns {Promise<{base64: string, mimeType: string}>} Base64 encoded audio.
 */
async function synthesiseSpeech({ text, voice = 'alloy', format = 'mp3', model = 'gpt-4o-mini-tts' }) {
  const apiKey = await getApiKey();
  ensureKeyAvailable(apiKey);
  const estimatedCost = 0.01;
  if (!costTracker.canSpend(estimatedCost)) {
    throw new Error('Cost limit reached for speech synthesis.');
  }

  const response = await fetch(`https://api.openai.com/v1/audio/speech`, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      Authorization: `Bearer ${apiKey}`,
    },
    body: JSON.stringify({
      model,
      voice,
      input: text,
      format,
    }),
  });

  if (!response.ok) {
    const message = await response.text();
    throw new Error(`Speech synthesis failed (${response.status}): ${message}`);
  }

  const arrayBuffer = await response.arrayBuffer();
  costTracker.recordFlat('tts', estimatedCost, { type: 'tts' });
  await persistUsage();
  return {
    base64: toBase64(arrayBuffer),
    mimeType: response.headers.get('content-type') || `audio/${format}`,
  };
}

/**
 * Retrieves a cached summary or requests a new one when necessary.
 *
 * @param {Object} params - Summary lookup options.
 * @param {string} params.url - Page URL used for cache grouping.
 * @param {{id: string, text: string}} params.segment - Segment to summarise.
 * @param {string} params.language - Output language code.
 * @returns {Promise<string>} Summary text for the segment.
 */
async function getSummary({ url, segment, language }) {
  const cacheKey = getCacheKey(url, segment.id);
  if (memoryCache.has(cacheKey)) {
    return memoryCache.get(cacheKey);
  }
  const estimatedCost = costTracker.estimateCostForText('gpt-4o-mini', segment.text);
  if (!costTracker.canSpend(estimatedCost)) {
    throw new Error('Cost limit reached for summaries.');
  }
  const summary = await sendChatCompletion({
    text: segment.text,
    url,
    segmentId: segment.id,
    language,
  });
  memoryCache.set(cacheKey, summary);
  await persistCache();
  return summary;
}

/**
 * Handles a summarisation request from the popup by processing each segment in
 * sequence while keeping track of usage.
 *
 * @param {{payload: {url: string, segments: Array<{id: string, text: string}>, language: string}}} message - Runtime message payload.
 * @returns {Promise<{summaries: Array<{id: string, summary: string}>, usage: Object}>}
 *   Summaries paired with the latest usage snapshot.
 */
async function handleSummariseRequest(message) {
  const { url, segments, language = 'en' } = message.payload;
  await ensureInitialised();
  const summaries = [];
  for (const segment of segments) {
    const summary = await getSummary({ url, segment, language });
    summaries.push({ id: segment.id, summary });
  }
  return { summaries, usage: costTracker.toJSON() };
}

/**
 * Handles speech-to-text requests triggered from the popup.
 *
 * @param {{payload: Object}} message - Runtime message including audio payload.
 * @returns {Promise<{text: string, usage: Object}>} Transcription and usage.
 */
async function handleTranscriptionRequest(message) {
  await ensureInitialised();
  const result = await transcribeAudio(message.payload);
  return { text: result, usage: costTracker.toJSON() };
}

/**
 * Handles text-to-speech requests triggered from the popup.
 *
 * @param {{payload: Object}} message - Runtime message including synthesis data.
 * @returns {Promise<{audio: Object, usage: Object}>} Encoded audio and usage.
 */
async function handleSpeechRequest(message) {
  await ensureInitialised();
  const result = await synthesiseSpeech(message.payload);
  return { audio: result, usage: costTracker.toJSON() };
}

/**
 * Retrieves the current usage snapshot.
 *
 * @returns {Promise<Object>} Usage data including limits and request history.
 */
async function handleUsageRequest() {
  await ensureInitialised();
  return costTracker.toJSON();
}

/**
 * Resets the accumulated usage statistics.
 *
 * @returns {Promise<Object>} Cleared usage data after reset.
 */
async function handleResetUsage() {
  await ensureInitialised();
  costTracker.reset();
  await persistUsage();
  return costTracker.toJSON();
}

/**
 * Synchronises the in-memory cache when the content script reports updated
 * segments, pruning entries that are no longer relevant.
 *
 * @param {{payload: {url: string, segments: Array<{id: string}>}}} message -
 *   Message containing the latest segment metadata.
 * @returns {Promise<boolean>} True once the cache has been updated.
 */
async function handleSegmentsUpdated(message) {
  const { url, segments } = message.payload;
  memoryCache.forEach((value, key) => {
    if (key.startsWith(`${url}::`)) {
      const exists = segments.some(segment => getCacheKey(url, segment.id) === key);
      if (!exists) {
        memoryCache.delete(key);
      }
    }
  });
  await persistCache();
  return true;
}

const handlers = {
  'comet:setApiKey': ({ payload }) => setApiKey(payload.apiKey),
  'comet:getApiKey': () => getApiKey(),
  'comet:getApiKeyDetails': () => getApiKeyDetails(),
  'comet:summarise': handleSummariseRequest,
  'comet:transcribe': handleTranscriptionRequest,
  'comet:synthesise': handleSpeechRequest,
  'comet:getUsage': handleUsageRequest,
  'comet:resetUsage': handleResetUsage,
  'comet:segmentsUpdated': handleSegmentsUpdated,
};

runtime.runtime.onMessage.addListener((message, sender, sendResponse) => {
  if (!message || !message.type || !handlers[message.type]) {
    return false;
  }

  const handler = handlers[message.type];
  Promise.resolve(handler(message, sender))
    .then(result => sendResponse({ ok: true, result }))
    .catch(error => {
      console.error('Comet background error', error);
      sendResponse({ ok: false, error: error.message });
    });

  return true;
});

export { ensureInitialised, getApiKeyDetails, handleUsageRequest, setApiKey };

ensureInitialised().catch(error => {
  console.error('Failed to initialise service worker', error);
});
