# API keys for supported language model providers.
# Copy this file to `.env` and fill in the keys for the providers you intend to use.
# Only define the variables you need; unset values will fall back to provider defaults.

# OpenAI compatible key (https://platform.openai.com/).
OPENAI_API_KEY=your-openai-api-key
# Anthropic Claude key (https://console.anthropic.com/).
ANTHROPIC_API_KEY=your-anthropic-api-key
# Mistral AI key (https://auth.mistral.ai/).
MISTRAL_API_KEY=your-mistral-api-key
# Hugging Face Inference endpoint token (https://huggingface.co/settings/tokens).
HUGGINGFACE_API_KEY=your-huggingface-api-token
# Ollama local runtime key; leave blank if your instance does not require authentication.
OLLAMA_API_KEY=your-ollama-api-key

# Optional overrides for self-hosted or proxy deployments.
# Example: http://localhost:11434 for a local Ollama instance.
OLLAMA_API_URL=http://localhost:11434
# Example: https://api.openai.com for the OpenAI public endpoint.
OPENAI_API_URL=https://api.openai.com
# Provide any additional provider specific URLs below.
# CUSTOM_PROVIDER_API_URL=https://your-custom-endpoint
